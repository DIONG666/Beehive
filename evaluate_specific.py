"""
FRAMESåŸºå‡†è¯„æµ‹è„šæœ¬ - æŒ‡å®šç´¢å¼•ç‰ˆæœ¬
æ”¯æŒæŒ‡å®šç‰¹å®šçš„indexåˆ—è¡¨è¿›è¡Œè¯„æµ‹ï¼Œå¹¶è¦†ç›–åŸæœ‰ç»“æœ

ä½¿ç”¨æ–¹æ³•ï¼š
1. ä»£ç å†…é…ç½®ï¼ˆæ¨èï¼‰ï¼š
   ä¿®æ”¹main()å‡½æ•°ä¸­çš„TARGET_INDICESåˆ—è¡¨ï¼Œç„¶åç›´æ¥è¿è¡Œï¼š
   python evaluate_specific.py

2. å‘½ä»¤è¡Œå‚æ•°ï¼š
   python evaluate_specific.py --indices "0,1,2"
   python evaluate_specific.py --indices "0-5"
   python evaluate_specific.py --indices "0,2-4,6"

3. é‡æµ‹FALSEç»“æœï¼š
   python evaluate_specific.py --retest-false --start-index 100

4. é‡æµ‹å­ä¸²åŒ¹é…FALSEç»“æœï¼š
   python evaluate_specific.py --retest-substring-false --start-index 0

5. æŸ¥çœ‹åˆ†ææŠ¥å‘Šï¼š
   python evaluate_specific.py --show-false-summary
   python evaluate_specific.py --show-substring-details
   python evaluate_specific.py --check-substring-accuracy

ç¤ºä¾‹é…ç½®ï¼š
TARGET_INDICES = [0, 1, 2]           # è¯„æµ‹ç´¢å¼•0,1,2
TARGET_INDICES = list(range(0, 10))  # è¯„æµ‹ç´¢å¼•0-9
TARGET_INDICES = [0, 5, 10, 15]      # è¯„æµ‹ç‰¹å®šç´¢å¼•
RETEST_SUBSTRING_FALSE = True        # é‡æµ‹åŒ…å«ç­”æ¡ˆä½†ä¸ºFALSEçš„ç»“æœ
"""
import argparse
import json
import os
import time
import io
import sys
from typing import List, Dict, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import Config
from openai import OpenAI
from datasets import load_dataset
from tqdm import tqdm

# é…ç½®DeepSeekå®¢æˆ·ç«¯ç”¨äºè¯„ä¼°
DEEPSEEK_CLIENT = None

def init_deepseek_client():
    """åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯"""
    global DEEPSEEK_CLIENT
    api_key = Config.DEEPSEEK_API_KEY
    if not api_key:
        raise ValueError("DEEPSEEK_API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®")
    
    DEEPSEEK_CLIENT = OpenAI(
        api_key=api_key,
        base_url=Config.DEEPSEEK_BASE_URL
    )

def load_existing_results(filename: str) -> List[Dict]:
    """åŠ è½½å·²æœ‰çš„è¯„æµ‹ç»“æœ"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []

def save_results(filename: str, results: List[Dict]):
    """ä¿å­˜å®Œæ•´çš„è¯„æµ‹ç»“æœåˆ—è¡¨"""
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

def update_result_by_index(results: List[Dict], new_result: Dict) -> List[Dict]:
    """
    æ ¹æ®indexæ›´æ–°ç»“æœåˆ—è¡¨ä¸­çš„å¯¹åº”é¡¹ç›®
    
    Args:
        results: ç°æœ‰ç»“æœåˆ—è¡¨
        new_result: æ–°çš„ç»“æœé¡¹ç›®
        
    Returns:
        æ›´æ–°åçš„ç»“æœåˆ—è¡¨
    """
    target_index = new_result.get('index')
    
    # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨è¯¥indexçš„ç»“æœ
    for i, result in enumerate(results):
        if result.get('index') == target_index:
            results[i] = new_result
            print(f"âœ… å·²è¦†ç›–ç´¢å¼• {target_index} çš„ç»“æœ")
            return results
    
    # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æ·»åŠ æ–°ç»“æœ
    results.append(new_result)
    print(f"âœ… å·²æ·»åŠ ç´¢å¼• {target_index} çš„æ–°ç»“æœ")
    return results

def generate_research_prompt(prompt: str, wiki_links: List[str]) -> str:
    """ç”Ÿæˆç ”ç©¶æç¤º"""
    if wiki_links:
        return f"æ ¹æ®ä»¥ä¸‹Wikipediaèµ„æºå›ç­”é—®é¢˜:\n{wiki_links}\n\né—®é¢˜: {prompt}"
    else:
        return f"é—®é¢˜: {prompt}"

def get_system_response(query: str, context: str = "") -> Dict[str, Any]:
    """
    ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè·å–å›ç­”
    
    Args:
        query: æŸ¥è¯¢é—®é¢˜
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
    Returns:
        ç³»ç»Ÿå›ç­”ç»“æœ
    """
    try:
        # å¯¼å…¥ç³»ç»Ÿ
        from main import MultiAgentResearchSystem
        system = MultiAgentResearchSystem()
        
        # è°ƒç”¨ç³»ç»Ÿ
        result = system.research_query(query, context)
        return result
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè°ƒç”¨å¤±è´¥: {str(e)}")
        return {
            'answer': f"ç³»ç»Ÿé”™è¯¯: {str(e)}",
            'citations': [],
            'reasoning_trace': "",
            'error': str(e)
        }

def evaluate_response_with_deepseek(question: str, system_response: str, ground_truth: str) -> Dict[str, str]:
    """
    ä½¿ç”¨DeepSeek-R1è¯„ä¼°å›ç­”çš„æ­£ç¡®æ€§
    
    Args:
        question: åŸå§‹é—®é¢˜
        system_response: ç³»ç»Ÿå›ç­”
        ground_truth: æ ‡å‡†ç­”æ¡ˆ
        
    Returns:
        è¯„ä¼°ç»“æœ (decision, explanation)
    """
    evaluation_prompt = f"""===ä»»åŠ¡===
æˆ‘éœ€è¦ä½ å¸®åŠ©è¯„ä¼°ä¸€ä¸ªAIç³»ç»Ÿæä¾›çš„ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„åŒ¹é…ç¨‹åº¦ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­æ ‡å‡†ç­”æ¡ˆçš„å†…å®¹æ˜¯å¦åœ¨AIç³»ç»Ÿçš„å›ç­”ä¸­ä½“ç°ã€‚

===æŒ‡å¯¼åŸåˆ™===
1. ä»”ç»†æ¯”è¾ƒ"AIç³»ç»Ÿå›ç­”"ä¸"æ ‡å‡†ç­”æ¡ˆ"ã€‚
2. å…³æ³¨ç­”æ¡ˆçš„å®è´¨å†…å®¹ - å¯»æ‰¾ç­‰ä»·ä¿¡æ¯æˆ–æ­£ç¡®ç­”æ¡ˆã€‚
3. ä¸è¦è¿‡åˆ†å…³æ³¨ç¡®åˆ‡çš„æªè¾ï¼Œé™¤éç¡®åˆ‡æªè¾å¯¹æ„ä¹‰è‡³å…³é‡è¦ã€‚
4. ä½ çš„æœ€ç»ˆå†³å®šåº”åŸºäº"æ ‡å‡†ç­”æ¡ˆ"çš„å«ä¹‰å’Œé‡è¦äº‹å®æ˜¯å¦åœ¨"AIç³»ç»Ÿå›ç­”"ä¸­ä½“ç°ã€‚
5. å¦‚æœAIç³»ç»Ÿå›ç­”ä¸­æ­£ç¡®å›ç­”äº†æ ‡å‡†ç­”æ¡ˆä¸­çš„å…³é”®ä¿¡æ¯æˆ–ç­‰ä»·å†…å®¹ï¼Œåˆ™è®¤ä¸ºæ˜¯æ­£ç¡®çš„ã€‚æ¯”å¦‚è¯¢é—®"How old was the journalist who reviewed the first iPad for the Wall St Journal when the first iPad came out?"ï¼Œå°½ç®¡æ ‡å‡†ç­”æ¡ˆä¸­è¿˜ä¼šæåˆ°è®°è€…çš„åå­—ï¼Œä½†æ˜¯åªè¦ç³»ç»Ÿå›ç­”äº†è®°è€…çš„å¹´é¾„ï¼Œå°±è®¤ä¸ºæ˜¯æ­£ç¡®çš„ã€‚

===è¾“å…¥æ•°æ®===
- é—®é¢˜: {question}
- AIç³»ç»Ÿå›ç­”: {system_response}
- æ ‡å‡†ç­”æ¡ˆ: {ground_truth}

===è¾“å‡ºæ ¼å¼===
ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¾“å‡ºæ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå…¶å®ƒæ— å…³å†…å®¹ï¼š
<explanation>(ä½ æ˜¯å¦‚ä½•åšå‡ºå†³å®šçš„?)</explanation>
<decision>("TRUE" æˆ– "FALSE")</decision>

è¯·å¼€å§‹è¯„ä¼°ã€‚"""

    try:
        evaluation_response = DEEPSEEK_CLIENT.chat.completions.create(
            model=Config.DEEPSEEK_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå®¢è§‚å…¬æ­£çš„AIè¯„ä¼°åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": evaluation_prompt}
            ],
            max_tokens=4096,
            temperature=0.3,
        )
        
        evaluation_text = evaluation_response.choices[0].message.content.strip()
        print(f"ğŸ“‹ DeepSeekè¯„ä¼°ç»“æœ:\n{evaluation_text}")
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ ‡ç­¾å†…å®¹
        import re
        
        # æå– <explanation> æ ‡ç­¾å†…å®¹
        explanation_match = re.search(r'<explanation>(.*?)</explanation>', evaluation_text, re.DOTALL | re.IGNORECASE)
        explanation = explanation_match.group(1).strip() if explanation_match else ""
        
        # æå– <decision> æ ‡ç­¾å†…å®¹
        decision_match = re.search(r'<decision>(.*?)</decision>', evaluation_text, re.DOTALL | re.IGNORECASE)
        decision_text = decision_match.group(1).strip() if decision_match else ""
        
        # å¤„ç†å†³å®šç»“æœ
        decision = "FALSE"  # é»˜è®¤å€¼
        if decision_text:
            decision_upper = decision_text.upper()
            if "TRUE" in decision_upper:
                decision = "TRUE"
            elif "FALSE" in decision_upper:
                decision = "FALSE"
        
        # å¦‚æœæ ‡ç­¾æå–å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰
        if not explanation and not decision_text:
            print("âš ï¸ æ ‡ç­¾æå–å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
            lines = evaluation_text.split('\n')
            for line in lines:
                line = line.strip()
                if "å†³å®š:" in line or "Decision:" in line:
                    decision_part = line.split(":", 1)[1].strip().upper()
                    if "TRUE" in decision_part:
                        decision = "TRUE"
                    elif "FALSE" in decision_part:
                        decision = "FALSE"
                elif "è§£é‡Š:" in line or "Explanation:" in line:
                    explanation = line.split(":", 1)[1].strip()
        
        return {"decision": decision, "explanation": explanation}
        
    except Exception as e:
        print(f"âŒ DeepSeekè¯„ä¼°å¤±è´¥: {str(e)}")
        return {"decision": "FALSE", "explanation": f"è¯„ä¼°é”™è¯¯: {str(e)}"}

def process_single_item(item: Dict[str, Any], index: int) -> Dict[str, Any]:
    """
    å¤„ç†å•ä¸ªè¯„æµ‹é¡¹ç›®
    
    Args:
        item: æ•°æ®é›†é¡¹ç›®
        index: é¡¹ç›®ç´¢å¼•
        
    Returns:
        å¤„ç†ç»“æœ
    """
    # æå–é—®é¢˜ä¿¡æ¯
    question = item.get('Prompt')
    ground_truth = item.get('Answer')
    reasoning_type = item.get('reasoning_types')
    wiki_links = item.get('wiki_links')
    # prompt = generate_research_prompt(question, wiki_links)
    prompt = question

    if not question:
        return {
            'index': index,
            'error': 'Question not found in item',
            'evaluation_decision': 'FALSE'
        }
    
    print(f"ğŸ“ å¤„ç†é—®é¢˜ {index}: {question[:100]}...")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè·å–å›ç­”
    try:
        system_result = get_system_response(prompt)
        system_answer = system_result.get('answer', '')
        system_citations = system_result.get('citations', [])
        reasoning_trace = system_result.get('reasoning_trace', "")
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè°ƒç”¨å¤±è´¥: {str(e)}")
        return {
            'index': index,
            'question': question,
            'ground_truth': ground_truth,
            'system_answer': f"ç³»ç»Ÿé”™è¯¯: {str(e)}",
            'evaluation_decision': 'FALSE',
            'evaluation_explanation': f"ç³»ç»Ÿé”™è¯¯: {str(e)}",
            'reasoning_type': reasoning_type,
            'response_time': 0,
            'error': str(e)
        }
    
    # è®°å½•å“åº”æ—¶é—´
    response_time = time.time() - start_time
    
    print(f"ğŸ’¡ ç³»ç»Ÿå›ç­”: {system_answer[:100]}...")
    print(f"â±ï¸ å“åº”æ—¶é—´: {response_time:.2f}ç§’")
    
    # ä½¿ç”¨DeepSeekè¯„ä¼°ç­”æ¡ˆ
    print("ğŸ” æ­£åœ¨è¯„ä¼°ç­”æ¡ˆ...")
    evaluation = evaluate_response_with_deepseek(question, system_answer, ground_truth)
    
    print(f"âœ… è¯„ä¼°ç»“æœ: {evaluation['decision']}")
    
    return {
        'index': index,
        'question': question,
        'ground_truth': ground_truth,
        'system_answer': system_answer,
        'system_citations': system_citations,
        'reasoning_trace': reasoning_trace,
        'evaluation_decision': evaluation['decision'],
        'evaluation_explanation': evaluation['explanation'],
        'reasoning_type': reasoning_type,
        'response_time': response_time,
    }

def parse_indices(indices_str: str) -> List[int]:
    """
    è§£æç´¢å¼•å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    Args:
        indices_str: ç´¢å¼•å­—ç¬¦ä¸²ï¼Œæ”¯æŒæ ¼å¼ï¼š
                    - "1,2,3" (é€—å·åˆ†éš”)
                    - "1-5" (èŒƒå›´)
                    - "1,3-5,7" (æ··åˆ)
                    
    Returns:
        ç´¢å¼•åˆ—è¡¨
    """
    indices = set()
    
    # æŒ‰é€—å·åˆ†å‰²
    parts = indices_str.split(',')
    
    for part in parts:
        part = part.strip()
        if '-' in part:
            # å¤„ç†èŒƒå›´
            start, end = part.split('-')
            start, end = int(start.strip()), int(end.strip())
            indices.update(range(start, end + 1))
        else:
            # å¤„ç†å•ä¸ªæ•°å­—
            indices.add(int(part))
    
    return sorted(list(indices))

def get_false_indices(results_file: str, start_index: int = 0) -> List[int]:
    """
    ä»ç»“æœæ–‡ä»¶ä¸­æå–è¯„æµ‹ç»“æœä¸ºFALSEçš„ç´¢å¼•
    
    Args:
        results_file: ç»“æœæ–‡ä»¶è·¯å¾„
        start_index: å¼€å§‹æ£€æµ‹çš„ç´¢å¼•ä½ç½®ï¼ˆé»˜è®¤ä¸º0ï¼Œå³ä»å¤´å¼€å§‹ï¼‰
        
    Returns:
        è¯„æµ‹ç»“æœä¸ºFALSEçš„ç´¢å¼•åˆ—è¡¨ï¼ˆåªåŒ…å« >= start_index çš„ç´¢å¼•ï¼‰
    """
    try:
        results = load_existing_results(results_file)
        false_indices = []
        
        for result in results:
            if result.get('evaluation_decision') == 'FALSE':
                index = result.get('index')
                if index is not None and index >= start_index:
                    false_indices.append(index)
        
        return sorted(false_indices)
        
    except Exception as e:
        print(f"âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}")
        return []

def show_false_results_summary(results_file: str, start_index: int = 0):
    """
    æ˜¾ç¤ºFALSEç»“æœçš„è¯¦ç»†æ‘˜è¦
    
    Args:
        results_file: ç»“æœæ–‡ä»¶è·¯å¾„
        start_index: èµ·å§‹ç´¢å¼•ï¼Œåªæ˜¾ç¤º >= start_index çš„FALSEç»“æœ
    """
    try:
        results = load_existing_results(results_file)
        false_results = [r for r in results if r.get('evaluation_decision') == 'FALSE' and r.get('index', 0) >= start_index]
        
        if not false_results:
            print(f"âœ… æ²¡æœ‰æ‰¾åˆ°ç´¢å¼• >= {start_index} çš„FALSEç»“æœ")
            return
            
        print(f"\nğŸ“Š FALSEç»“æœæ‘˜è¦ï¼ˆä»ç´¢å¼• {start_index} å¼€å§‹ï¼Œå…± {len(false_results)} ä¸ªï¼‰:")
        print("-" * 60)
        
        # æŒ‰æ¨ç†ç±»å‹åˆ†ç»„
        from collections import defaultdict
        by_reasoning_type = defaultdict(list)
        
        for result in false_results:
            reasoning_type = result.get('reasoning_type', 'unknown')
            by_reasoning_type[reasoning_type].append(result.get('index'))
        
        for reasoning_type, indices in by_reasoning_type.items():
            print(f"ğŸ“ˆ {reasoning_type}: {len(indices)} ä¸ª")
            print(f"   ç´¢å¼•: {indices[:10]}{'...' if len(indices) > 10 else ''}")
        
        false_indices = [r.get('index') for r in false_results]
        print(f"\nğŸ”¢ æ‰€æœ‰FALSEç´¢å¼•ï¼ˆ>= {start_index}ï¼‰: {false_indices}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}")

def find_false_with_substring_match(results_file: str, start_index: int = 0, case_sensitive: bool = False) -> List[int]:
    """
    æ‰¾å‡ºç³»ç»Ÿå›ç­”åŒ…å«æ ‡å‡†ç­”æ¡ˆä½œä¸ºå­ä¸²ä½†è¢«è¯„ä¸ºFALSEçš„ç´¢å¼•
    
    Args:
        results_file: ç»“æœæ–‡ä»¶è·¯å¾„
        start_index: å¼€å§‹æ£€æµ‹çš„ç´¢å¼•ä½ç½®
        case_sensitive: æ˜¯å¦åŒºåˆ†å¤§å°å†™ï¼ˆé»˜è®¤ä¸åŒºåˆ†ï¼‰
        
    Returns:
        ç¬¦åˆæ¡ä»¶çš„ç´¢å¼•åˆ—è¡¨
    """
    try:
        results = load_existing_results(results_file)
        substring_false_indices = []
        
        for result in results:
            if (result.get('evaluation_decision') == 'FALSE' and 
                result.get('index', 0) >= start_index):
                
                system_answer = result.get('system_answer', '')
                ground_truth = result.get('ground_truth', '')
                
                if system_answer and ground_truth:
                    # æ ¹æ®æ˜¯å¦åŒºåˆ†å¤§å°å†™è¿›è¡Œæ¯”è¾ƒ
                    if case_sensitive:
                        contains_truth = system_answer in ground_truth
                    else:
                        contains_truth = system_answer.lower() in ground_truth.lower()

                    if contains_truth:
                        substring_false_indices.append(result.get('index'))
        
        return sorted(substring_false_indices)
        
    except Exception as e:
        print(f"âŒ æŸ¥æ‰¾å­ä¸²åŒ¹é…å¤±è´¥: {str(e)}")
        return []

def show_substring_false_details(results_file: str, start_index: int = 0, case_sensitive: bool = False, max_display: int = 10):
    """
    æ˜¾ç¤ºåŒ…å«å­ä¸²ä½†è¢«è¯„ä¸ºFALSEçš„è¯¦ç»†ä¿¡æ¯
    
    Args:
        results_file: ç»“æœæ–‡ä»¶è·¯å¾„
        start_index: èµ·å§‹ç´¢å¼•
        case_sensitive: æ˜¯å¦åŒºåˆ†å¤§å°å†™
        max_display: æœ€å¤§æ˜¾ç¤ºæ¡æ•°
    """
    try:
        results = load_existing_results(results_file)
        substring_false_results = []
        
        for result in results:
            if (result.get('evaluation_decision') == 'FALSE' and 
                result.get('index', 0) >= start_index):
                
                system_answer = result.get('system_answer', '')
                ground_truth = result.get('ground_truth', '')
                
                if system_answer and ground_truth:
                    # æ ¹æ®æ˜¯å¦åŒºåˆ†å¤§å°å†™è¿›è¡Œæ¯”è¾ƒ
                    if case_sensitive:
                        contains_truth = ground_truth in system_answer
                    else:
                        contains_truth = ground_truth.lower() in system_answer.lower()
                    
                    if contains_truth:
                        substring_false_results.append(result)
        
        if not substring_false_results:
            print(f"âœ… æ²¡æœ‰æ‰¾åˆ°ç´¢å¼• >= {start_index} çš„å­ä¸²åŒ¹é…FALSEç»“æœ")
            return
        
        print(f"\nğŸ“Š å­ä¸²åŒ¹é…FALSEç»“æœè¯¦æƒ…ï¼ˆä»ç´¢å¼• {start_index} å¼€å§‹ï¼Œå…± {len(substring_false_results)} ä¸ªï¼‰:")
        print("=" * 80)
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªè¯¦ç»†æ¡ˆä¾‹
        display_count = min(max_display, len(substring_false_results))
        for i, result in enumerate(substring_false_results[:display_count]):
            index = result.get('index')
            question = result.get('question', '')[:100] + '...' if len(result.get('question', '')) > 100 else result.get('question', '')
            system_answer = result.get('system_answer', '')
            ground_truth = result.get('ground_truth', '')
            evaluation_explanation = result.get('evaluation_explanation', '')
            
            print(f"\nğŸ“ ç´¢å¼• {index}:")
            print(f"é—®é¢˜: {question}")
            print(f"æ ‡å‡†ç­”æ¡ˆ: {ground_truth}")
            print(f"ç³»ç»Ÿå›ç­”: {system_answer[:200]}{'...' if len(system_answer) > 200 else ''}")
            print(f"è¯„ä¼°è§£é‡Š: {evaluation_explanation[:150]}{'...' if len(evaluation_explanation) > 150 else ''}")
            
            # é«˜äº®æ˜¾ç¤ºåŒ¹é…éƒ¨åˆ†
            if case_sensitive:
                match_pos = system_answer.find(ground_truth)
            else:
                match_pos = system_answer.lower().find(ground_truth.lower())
            
            if match_pos >= 0:
                start_pos = max(0, match_pos - 50)
                end_pos = min(len(system_answer), match_pos + len(ground_truth) + 50)
                context = system_answer[start_pos:end_pos]
                print(f"ğŸ¯ åŒ¹é…ä¸Šä¸‹æ–‡: ...{context}...")
            
            print("-" * 60)
        
        if len(substring_false_results) > max_display:
            print(f"\n... è¿˜æœ‰ {len(substring_false_results) - max_display} ä¸ªç±»ä¼¼ç»“æœ")
        
        # æ˜¾ç¤ºæ‰€æœ‰ç´¢å¼•
        all_indices = [r.get('index') for r in substring_false_results]
        print(f"\nğŸ”¢ æ‰€æœ‰å­ä¸²åŒ¹é…FALSEç´¢å¼•: {all_indices}")
        
        # æŒ‰æ¨ç†ç±»å‹åˆ†ç»„ç»Ÿè®¡
        from collections import defaultdict
        by_reasoning_type = defaultdict(list)
        
        for result in substring_false_results:
            reasoning_type = result.get('reasoning_type', 'unknown')
            by_reasoning_type[reasoning_type].append(result.get('index'))
        
        print(f"\nğŸ“ˆ æŒ‰æ¨ç†ç±»å‹åˆ†ç»„:")
        for reasoning_type, indices in by_reasoning_type.items():
            print(f"  {reasoning_type}: {len(indices)} ä¸ª - {indices[:5]}{'...' if len(indices) > 5 else ''}")
        
    except Exception as e:
        print(f"âŒ æ˜¾ç¤ºè¯¦æƒ…å¤±è´¥: {str(e)}")

def check_substring_matching_accuracy(results_file: str, start_index: int = 0, case_sensitive: bool = False):
    """
    æ£€æŸ¥å­ä¸²åŒ¹é…çš„å‡†ç¡®æ€§ç»Ÿè®¡
    
    Args:
        results_file: ç»“æœæ–‡ä»¶è·¯å¾„  
        start_index: èµ·å§‹ç´¢å¼•
        case_sensitive: æ˜¯å¦åŒºåˆ†å¤§å°å†™
    """
    try:
        results = load_existing_results(results_file)
        
        # ç»Ÿè®¡å„ç§æƒ…å†µ
        total_false = 0
        substring_match_false = 0  # åŒ…å«å­ä¸²ä½†ä¸ºFALSE
        substring_match_true = 0   # åŒ…å«å­ä¸²ä¸”ä¸ºTRUE
        no_substring_false = 0     # ä¸åŒ…å«å­ä¸²ä¸”ä¸ºFALSE
        no_substring_true = 0      # ä¸åŒ…å«å­ä¸²ä½†ä¸ºTRUEï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
        
        for result in results:
            if result.get('index', 0) < start_index:
                continue
                
            system_answer = result.get('system_answer', '')
            ground_truth = result.get('ground_truth', '')
            evaluation_decision = result.get('evaluation_decision', 'FALSE')
            
            if system_answer and ground_truth:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å­ä¸²
                if case_sensitive:
                    contains_truth = ground_truth in system_answer
                else:
                    contains_truth = ground_truth.lower() in system_answer.lower()
                
                if evaluation_decision == 'FALSE':
                    total_false += 1
                    if contains_truth:
                        substring_match_false += 1
                    else:
                        no_substring_false += 1
                else:  # TRUE
                    if contains_truth:
                        substring_match_true += 1
                    else:
                        no_substring_true += 1
        
        print(f"\nğŸ“Š å­ä¸²åŒ¹é…å‡†ç¡®æ€§åˆ†æï¼ˆç´¢å¼• >= {start_index}ï¼‰:")
        print("=" * 50)
        print(f"ğŸ“‰ FALSEç»“æœæ€»æ•°: {total_false}")
        print(f"ğŸ¯ åŒ…å«æ ‡å‡†ç­”æ¡ˆä½†ä¸ºFALSE: {substring_match_false} ({substring_match_false/total_false*100:.1f}%)")
        print(f"âŒ ä¸åŒ…å«æ ‡å‡†ç­”æ¡ˆä¸”ä¸ºFALSE: {no_substring_false} ({no_substring_false/total_false*100:.1f}%)")
        print(f"âœ… åŒ…å«æ ‡å‡†ç­”æ¡ˆä¸”ä¸ºTRUE: {substring_match_true}")
        print(f"âš ï¸  ä¸åŒ…å«æ ‡å‡†ç­”æ¡ˆä½†ä¸ºTRUE: {no_substring_true} (å¯èƒ½çš„å¼‚å¸¸)")
        
        if substring_match_false > 0:
            print(f"\nğŸ’¡ å»ºè®®: æœ‰ {substring_match_false} ä¸ªç»“æœå¯èƒ½è¢«è¯¯åˆ¤ï¼Œå»ºè®®é‡æ–°è¯„ä¼°")
        
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡åˆ†æå¤±è´¥: {str(e)}")

def main():
    # ===== åœ¨è¿™é‡Œé…ç½®è¦è¯„æµ‹çš„ç´¢å¼•å’Œç»“æœæ–‡ä»¶ =====
    # ç›´æ¥åœ¨ä»£ç ä¸­å®šä¹‰è¦è¯„æµ‹çš„ç´¢å¼•åˆ—è¡¨
    TARGET_INDICES = [474,482,494,514,540,572,584,585,629,663,684,712,739,767,773,775]  # å¯ä»¥ä¿®æ”¹è¿™ä¸ªåˆ—è¡¨æ¥æŒ‡å®šè¦è¯„æµ‹çš„ç´¢å¼•
    
    RESULTS_FILE = 'frames_evaluation_multi_agent.json'  # ç»“æœæ–‡ä»¶å
    
    # é‡æµ‹æ¨¡å¼ï¼šæ˜¯å¦é‡æµ‹FALSEç»“æœ
    RETEST_FALSE_ONLY = True  # è®¾ç½®ä¸ºTrueæ—¶ï¼Œä¼šè‡ªåŠ¨æå–FALSEç»“æœè¿›è¡Œé‡æµ‹
    
    # å­ä¸²åŒ¹é…é‡æµ‹æ¨¡å¼ï¼šé‡æµ‹é‚£äº›åŒ…å«æ ‡å‡†ç­”æ¡ˆä½†è¢«è¯„ä¸ºFALSEçš„ç»“æœ
    RETEST_SUBSTRING_FALSE = False  # è®¾ç½®ä¸ºTrueæ—¶ï¼Œä¼šé‡æµ‹åŒ…å«å­ä¸²ä½†ä¸ºFALSEçš„ç»“æœ
    
    # FALSEé‡æµ‹çš„èµ·å§‹ç´¢å¼•ï¼ˆåªæœ‰å½“é‡æµ‹FALSEç»“æœæ—¶æ‰ç”Ÿæ•ˆï¼‰
    FALSE_START_INDEX = 0  # ä»è¿™ä¸ªç´¢å¼•å¼€å§‹æ£€æµ‹FALSEç»“æœï¼Œé»˜è®¤ä¸º0ï¼ˆä»å¤´å¼€å§‹ï¼‰
    
    # å­ä¸²åŒ¹é…æ˜¯å¦åŒºåˆ†å¤§å°å†™
    CASE_SENSITIVE = True  # é»˜è®¤ä¸åŒºåˆ†å¤§å°å†™
    
    # å¦‚æœå‘½ä»¤è¡Œå‚æ•°å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
    parser = argparse.ArgumentParser(description='FRAMESåŸºå‡†è¯„æµ‹ - æŒ‡å®šç´¢å¼•ç‰ˆæœ¬')
    parser.add_argument('--indices', type=str, required=False, 
                       help='è¦è¯„æµ‹çš„ç´¢å¼•åˆ—è¡¨ï¼Œæ”¯æŒæ ¼å¼ï¼š1,2,3 æˆ– 1-5 æˆ– 1,3-5,7')
    parser.add_argument('--results-file', type=str, 
                       default=RESULTS_FILE,
                       help='ç»“æœæ–‡ä»¶åï¼ˆé»˜è®¤ï¼šframes_evaluation_multi_agent.jsonï¼‰')
    parser.add_argument('--retest-false', action='store_true',
                       help='é‡æµ‹ç»“æœæ–‡ä»¶ä¸­è¯„æµ‹ä¸ºFALSEçš„é¡¹ç›®')
    parser.add_argument('--retest-substring-false', action='store_true',
                       help='é‡æµ‹åŒ…å«æ ‡å‡†ç­”æ¡ˆä½†è¢«è¯„ä¸ºFALSEçš„é¡¹ç›®')
    parser.add_argument('--start-index', type=int, default=FALSE_START_INDEX,
                       help='é‡æµ‹FALSEç»“æœæ—¶çš„èµ·å§‹ç´¢å¼•ï¼ˆé»˜è®¤ï¼š0ï¼‰')
    parser.add_argument('--show-false-summary', action='store_true',
                       help='ä»…æ˜¾ç¤ºFALSEç»“æœæ‘˜è¦ï¼Œä¸è¿›è¡Œè¯„æµ‹')
    parser.add_argument('--show-substring-details', action='store_true',
                       help='æ˜¾ç¤ºå­ä¸²åŒ¹é…FALSEç»“æœçš„è¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--check-substring-accuracy', action='store_true',
                       help='æ£€æŸ¥å­ä¸²åŒ¹é…çš„å‡†ç¡®æ€§ç»Ÿè®¡')
    parser.add_argument('--case-sensitive', action='store_true',
                       help='å­ä¸²åŒ¹é…æ—¶åŒºåˆ†å¤§å°å†™ï¼ˆé»˜è®¤ä¸åŒºåˆ†ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹FRAMESåŸºå‡†è¯„æµ‹ - æŒ‡å®šç´¢å¼•ç‰ˆæœ¬")
    print("="*60)
    
    # å‡†å¤‡ç»“æœæ–‡ä»¶è·¯å¾„
    results_file = args.results_file
    results_dir = os.path.join(Config.DATA_DIR, 'evaluation_results')
    os.makedirs(results_dir, exist_ok=True)
    full_filename = os.path.join(results_dir, results_file)
    
    # å¦‚æœåªæ˜¯è¦æ˜¾ç¤ºæ‘˜è¦ï¼Œåˆ™æ˜¾ç¤ºåé€€å‡º
    if args.show_false_summary:
        start_index = args.start_index if hasattr(args, 'start_index') else FALSE_START_INDEX
        show_false_results_summary(full_filename, start_index)
        return
    
    # å¦‚æœåªæ˜¯è¦æ˜¾ç¤ºå­ä¸²åŒ¹é…è¯¦æƒ…ï¼Œåˆ™æ˜¾ç¤ºåé€€å‡º
    if args.show_substring_details:
        start_index = args.start_index if hasattr(args, 'start_index') else FALSE_START_INDEX
        case_sensitive = args.case_sensitive if hasattr(args, 'case_sensitive') else CASE_SENSITIVE
        show_substring_false_details(full_filename, start_index, case_sensitive)
        return
    
    # å¦‚æœåªæ˜¯è¦æ£€æŸ¥å­ä¸²åŒ¹é…å‡†ç¡®æ€§ï¼Œåˆ™æ˜¾ç¤ºåé€€å‡º
    if args.check_substring_accuracy:
        start_index = args.start_index if hasattr(args, 'start_index') else FALSE_START_INDEX
        case_sensitive = args.case_sensitive if hasattr(args, 'case_sensitive') else CASE_SENSITIVE
        check_substring_matching_accuracy(full_filename, start_index, case_sensitive)
        return
    
    # ç¡®å®šä½¿ç”¨å“ªç§æ¨¡å¼è·å–ç´¢å¼•
    if args.retest_substring_false or RETEST_SUBSTRING_FALSE:
        # é‡æµ‹å­ä¸²åŒ¹é…FALSEç»“æœæ¨¡å¼
        start_index = args.start_index if hasattr(args, 'start_index') else FALSE_START_INDEX
        case_sensitive = args.case_sensitive if hasattr(args, 'case_sensitive') else CASE_SENSITIVE
        print(f"ğŸ¯ å­ä¸²åŒ¹é…é‡æµ‹æ¨¡å¼ï¼šé‡æµ‹åŒ…å«æ ‡å‡†ç­”æ¡ˆä½†è¢«è¯„ä¸ºFALSEçš„ç»“æœ")
        print(f"ğŸ“ èµ·å§‹ç´¢å¼•: {start_index}")
        print(f"ğŸ”¤ åŒºåˆ†å¤§å°å†™: {case_sensitive}")
        target_indices = find_false_with_substring_match(full_filename, start_index, case_sensitive)
        if not target_indices:
            print(f"â“ æœªæ‰¾åˆ°ç´¢å¼• >= {start_index} çš„å­ä¸²åŒ¹é…FALSEç»“æœ")
            return
        print(f"ğŸ“ æ‰¾åˆ° {len(target_indices)} ä¸ªå­ä¸²åŒ¹é…FALSEç»“æœå¾…é‡æµ‹ï¼ˆç´¢å¼•èŒƒå›´: {min(target_indices)}-{max(target_indices)}ï¼‰")
        
    elif args.retest_false or RETEST_FALSE_ONLY:
        # é‡æµ‹FALSEç»“æœæ¨¡å¼
        start_index = args.start_index if hasattr(args, 'start_index') else FALSE_START_INDEX
        print(f"ğŸ”„ é‡æµ‹æ¨¡å¼ï¼šä»ç»“æœæ–‡ä»¶ä¸­æå–FALSEç»“æœè¿›è¡Œé‡æµ‹")
        print(f"ğŸ“ èµ·å§‹ç´¢å¼•: {start_index}")
        target_indices = get_false_indices(full_filename, start_index)
        if not target_indices:
            print(f"â“ æœªæ‰¾åˆ°ç´¢å¼• >= {start_index} çš„FALSEç»“æœ")
            return
        print(f"ğŸ“ æ‰¾åˆ° {len(target_indices)} ä¸ªFALSEç»“æœå¾…é‡æµ‹ï¼ˆç´¢å¼•èŒƒå›´: {min(target_indices)}-{max(target_indices)}ï¼‰")
        
    elif args.indices:
        # å‘½ä»¤è¡Œå‚æ•°æ¨¡å¼
        try:
            target_indices = parse_indices(args.indices)
            print(f"ğŸ“ ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šçš„ç´¢å¼•")
        except Exception as e:
            print(f"âŒ å‘½ä»¤è¡Œç´¢å¼•è§£æå¤±è´¥: {str(e)}")
            return
            
    else:
        # ä»£ç å®šä¹‰æ¨¡å¼
        target_indices = TARGET_INDICES
        print(f"ğŸ“ ä½¿ç”¨ä»£ç ä¸­å®šä¹‰çš„ç´¢å¼•")
    
    print(f"ğŸ¯ ç›®æ ‡ç´¢å¼•: {target_indices}")
    print(f"ğŸ“Š å…± {len(target_indices)} ä¸ªé—®é¢˜å¾…è¯„æµ‹")
    print(f"ğŸ“‹ ç»“æœæ–‡ä»¶: {results_file}")
    
    # åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
    try:
        init_deepseek_client()
        print("âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return
    
    # åŠ è½½æ•°æ®é›†
    print(f"ğŸ“ åŠ è½½æ•°æ®é›†")
    dataset = load_dataset("google/frames-benchmark", split="test")
    
    if not dataset:
        print("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥")
        return
    
    print(f"ğŸ“Š æ•°æ®é›†åŒ…å« {len(dataset)} ä¸ªé—®é¢˜")
    
    # æ£€æŸ¥ç´¢å¼•æœ‰æ•ˆæ€§
    max_index = len(dataset) - 1
    invalid_indices = [idx for idx in target_indices if idx > max_index]
    if invalid_indices:
        print(f"âŒ æ— æ•ˆç´¢å¼•: {invalid_indices} (æ•°æ®é›†æœ€å¤§ç´¢å¼•: {max_index})")
        return
    
    # å‡†å¤‡ç»“æœæ–‡ä»¶
    results_dir = os.path.join(Config.DATA_DIR, 'evaluation_results')
    os.makedirs(results_dir, exist_ok=True)
    full_filename = os.path.join(results_dir, results_file)
    
    # åŠ è½½ç°æœ‰ç»“æœ
    existing_results = load_existing_results(full_filename)
    print(f"ğŸ“‹ ç»“æœæ–‡ä»¶: {full_filename}")
    print(f"ğŸ“ ç°æœ‰ç»“æœæ•°é‡: {len(existing_results)}")
    
    # å¦‚æœæ˜¯é‡æµ‹æ¨¡å¼ï¼Œæ˜¾ç¤ºå½“å‰FALSEç»“æœç»Ÿè®¡
    if args.retest_substring_false or RETEST_SUBSTRING_FALSE:
        false_count = len([r for r in existing_results if r.get('evaluation_decision') == 'FALSE'])
        total_count = len(existing_results)
        print(f"ğŸ” å½“å‰ç»“æœç»Ÿè®¡ï¼šFALSE: {false_count}, æ€»æ•°: {total_count}")
        print(f"ğŸ¯ å‡†å¤‡é‡æµ‹ {len(target_indices)} ä¸ªå­ä¸²åŒ¹é…FALSEç»“æœ")
    elif args.retest_false or RETEST_FALSE_ONLY:
        false_count = len([r for r in existing_results if r.get('evaluation_decision') == 'FALSE'])
        total_count = len(existing_results)
        print(f"ğŸ” å½“å‰ç»“æœç»Ÿè®¡ï¼šFALSE: {false_count}, æ€»æ•°: {total_count}")
        print(f"ğŸ”„ å‡†å¤‡é‡æµ‹ {len(target_indices)} ä¸ªFALSEç»“æœ")
    
    # å¤„ç†æŒ‡å®šçš„ç´¢å¼•
    processed_count = 0
    failed_count = 0
    
    for idx in tqdm(target_indices, desc="å¤„ç†æŒ‡å®šé—®é¢˜"):
        try:
            item = dataset[idx]
            result = process_single_item(item, idx)
            
            # æ›´æ–°ç»“æœåˆ—è¡¨
            existing_results = update_result_by_index(existing_results, result)
            
            # ä¿å­˜æ›´æ–°åçš„ç»“æœ
            save_results(full_filename, existing_results)
            
            processed_count += 1
            
        except Exception as e:
            print(f"âŒ å¤„ç†é—®é¢˜ {idx} å¤±è´¥: {str(e)}")
            failed_count += 1
            continue
    
    # è¾“å‡ºå¤„ç†ç»Ÿè®¡
    print("\n" + "="*60)
    print("ğŸ“Š å¤„ç†ç»Ÿè®¡")
    print("="*60)
    print(f"ç›®æ ‡é—®é¢˜æ•°: {len(target_indices)}")
    print(f"å¤„ç†æˆåŠŸ: {processed_count}")
    print(f"å¤„ç†å¤±è´¥: {failed_count}")
    
    # è®¡ç®—å¹¶è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    print("\n" + "="*60)
    print("ğŸ“Š æœ€ç»ˆè¯„æµ‹ç»Ÿè®¡")
    print("="*60)
    
    results = load_existing_results(full_filename)
    total_samples = len(results)
    correct_answers = sum(1 for r in results if r.get('evaluation_decision') == 'TRUE')
    accuracy = correct_answers / total_samples if total_samples > 0 else 0
    
    print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"æ­£ç¡®ç­”æ¡ˆ: {correct_answers}")
    print(f"å‡†ç¡®ç‡: {accuracy:.2%}")
    
    # æŒ‰æ¨ç†ç±»å‹ç»Ÿè®¡å‡†ç¡®ç‡
    reasoning_types = set(r.get('reasoning_type', 'unknown') for r in results)
    print(f"\nğŸ“ˆ æŒ‰æ¨ç†ç±»å‹ç»Ÿè®¡:")
    for rt in reasoning_types:
        rt_samples = [r for r in results if r.get('reasoning_type') == rt]
        if rt_samples:
            rt_correct = sum(1 for r in rt_samples if r.get('evaluation_decision') == 'TRUE')
            rt_accuracy = rt_correct / len(rt_samples)
            print(f"  {rt}: {rt_accuracy:.2%} ({rt_correct}/{len(rt_samples)})")
    
    # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    response_times = [r.get('response_time', 0) for r in results if r.get('response_time')]
    if response_times:
        avg_time = sum(response_times) / len(response_times)
        print(f"\nâ±ï¸ å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}ç§’")
    
    # æ˜¾ç¤ºæœ¬æ¬¡å¤„ç†çš„ç´¢å¼•ç»Ÿè®¡
    processed_results = [r for r in results if r.get('index') in target_indices]
    if processed_results:
        processed_correct = sum(1 for r in processed_results if r.get('evaluation_decision') == 'TRUE')
        processed_accuracy = processed_correct / len(processed_results) if processed_results else 0
        print(f"\nğŸ¯ æœ¬æ¬¡å¤„ç†çš„ç´¢å¼•ç»Ÿè®¡:")
        print(f"  å¤„ç†é—®é¢˜æ•°: {len(processed_results)}")
        print(f"  æ­£ç¡®ç­”æ¡ˆ: {processed_correct}")
        print(f"  å‡†ç¡®ç‡: {processed_accuracy:.2%}")
    
    print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {full_filename}")

if __name__ == "__main__":
    main()
