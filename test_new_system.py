"""
æ–°ç³»ç»Ÿæµç¨‹æ¼”ç¤ºè„šæœ¬
"""
import asyncio
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from agent.main_agent import MainAgent


async def test_new_system():
    """æµ‹è¯•æ–°çš„ç³»ç»Ÿæµç¨‹"""
    print("ğŸš€ æ–°å¤šæ™ºèƒ½ä½“ç ”ç©¶ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # æ£€æŸ¥åŸºæœ¬é…ç½®
    print("ğŸ“‹ æ£€æŸ¥ç³»ç»Ÿé…ç½®...")
    config = Config()
    
    if not config.DEEPSEEK_API_KEY:
        print("âš ï¸ è­¦å‘Š: DEEPSEEK_API_KEY æœªè®¾ç½®")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export DEEPSEEK_API_KEY='your_key'")
        return
    
    print("âœ… é…ç½®æ£€æŸ¥å®Œæˆ")
    
    # åˆå§‹åŒ–ä¸»æ™ºèƒ½ä½“
    print("\nğŸ¤– åˆå§‹åŒ–ä¸»æ™ºèƒ½ä½“...")
    agent = MainAgent()
    
    # æµ‹è¯•æŸ¥è¯¢åˆ†è§£ï¼ˆåŒ…å«Wikipediaé“¾æ¥ï¼‰
    print("\nğŸ“‹ æµ‹è¯•1: åŒ…å«Wikipediaé“¾æ¥çš„æŸ¥è¯¢")
    query_with_links = """
    è¯·å‘Šè¯‰æˆ‘å…³äºäººå·¥æ™ºèƒ½çš„ä¿¡æ¯ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹èµ„æºï¼š
    https://en.wikipedia.org/wiki/Artificial_intelligence
    https://en.wikipedia.org/wiki/Machine_learning
    """
    
    try:
        result1 = await agent.execute_reasoning(query_with_links)
        print("âœ… æµ‹è¯•1å®Œæˆ")
        print(f"ç­”æ¡ˆé•¿åº¦: {len(result1.get('answer', ''))}")
        print(f"å¼•ç”¨æ•°é‡: {len(result1.get('citations', []))}")
        print(f"æ¨ç†æ­¥éª¤: {len(result1.get('reasoning_trace', []))}")
    except Exception as e:
        print(f"âŒ æµ‹è¯•1å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•æŸ¥è¯¢åˆ†è§£ï¼ˆä¸åŒ…å«é“¾æ¥ï¼‰
    print("\nğŸ“‹ æµ‹è¯•2: æ™®é€šæŸ¥è¯¢åˆ†è§£")
    normal_query = "What are the main types of machine learning algorithms and their applications?"
    
    try:
        result2 = await agent.execute_reasoning(normal_query)
        print("âœ… æµ‹è¯•2å®Œæˆ")
        print(f"ç­”æ¡ˆé•¿åº¦: {len(result2.get('answer', ''))}")
        print(f"å¼•ç”¨æ•°é‡: {len(result2.get('citations', []))}")
        print(f"æ¨ç†æ­¥éª¤: {len(result2.get('reasoning_trace', []))}")
        
        # æ˜¾ç¤ºæ¨ç†è½¨è¿¹
        print("\nğŸ“ æ¨ç†è½¨è¿¹:")
        for i, step in enumerate(result2.get('reasoning_trace', [])[:3], 1):
            print(f"{i}. {step[:100]}...")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•2å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºæ™ºèƒ½ä½“ä¿¡æ¯
    print("\nğŸ” æ™ºèƒ½ä½“ä¿¡æ¯:")
    agent_info = agent.get_agent_info()
    print(f"ç±»å‹: {agent_info['agent_type']}")
    print(f"å¯ç”¨å·¥å…·: {agent_info['available_tools']}")
    print(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {agent_info['max_iterations']}")
    print(f"èƒ½åŠ›åˆ—è¡¨: {', '.join(agent_info['reasoning_capabilities'])}")


async def test_frames_like_query():
    """æµ‹è¯•ç±»ä¼¼FRAMESæ ¼å¼çš„æŸ¥è¯¢"""
    print("\nğŸ¯ æµ‹è¯•FRAMESé£æ ¼æŸ¥è¯¢")
    print("=" * 50)
    
    agent = MainAgent()
    
    # æ¨¡æ‹ŸFRAMESæ•°æ®é›†ä¸­çš„æŸ¥è¯¢
    frames_query = """
    What is the relationship between deep learning and neural networks? 
    Please explain the key concepts and provide examples of applications.
    """
    
    try:
        result = await agent.execute_reasoning(frames_query)
        
        print("ğŸ“Š æŸ¥è¯¢ç»“æœ:")
        print(f"ç­”æ¡ˆ: {result.get('answer', 'No answer')[:200]}...")
        print(f"æ¥æºæ•°é‡: {len(result.get('search_results', []))}")
        print(f"è¿­ä»£æ¬¡æ•°: {result.get('metadata', {}).get('iterations', 0)}")
        
        # è¯„ä¼°ç­”æ¡ˆè´¨é‡æŒ‡æ ‡
        answer = result.get('answer', '')
        citations = result.get('citations', [])
        
        quality_metrics = {
            'has_answer': len(answer) > 50,
            'has_citations': len(citations) > 0,
            'comprehensive': len(answer) > 200,
            'structured': 'ã€‚' in answer or '.' in answer,
            'evidence_based': len(result.get('search_results', [])) > 0
        }
        
        print("\nğŸ“ˆ ç­”æ¡ˆè´¨é‡è¯„ä¼°:")
        for metric, value in quality_metrics.items():
            status = "âœ…" if value else "âŒ"
            print(f"{status} {metric}: {value}")
        
        overall_score = sum(quality_metrics.values()) / len(quality_metrics)
        print(f"\nğŸ¯ æ€»ä½“è´¨é‡åˆ†æ•°: {overall_score:.2f}")
        
    except Exception as e:
        print(f"âŒ FRAMESæµ‹è¯•å¤±è´¥: {str(e)}")


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒè®¾ç½®"""
    print("ğŸ”§ ç¯å¢ƒæ£€æŸ¥")
    print("=" * 30)
    
    required_vars = ['DEEPSEEK_API_KEY']
    optional_vars = ['JINA_API_KEY', 'BING_API_KEY']
    
    print("å¿…éœ€çš„ç¯å¢ƒå˜é‡:")
    for var in required_vars:
        value = os.getenv(var)
        status = "âœ…" if value else "âŒ"
        print(f"{status} {var}: {'å·²è®¾ç½®' if value else 'æœªè®¾ç½®'}")
    
    print("\nå¯é€‰çš„ç¯å¢ƒå˜é‡:")
    for var in optional_vars:
        value = os.getenv(var)
        status = "âœ…" if value else "âš ï¸"
        print(f"{status} {var}: {'å·²è®¾ç½®' if value else 'æœªè®¾ç½®'}")
    
    print("\nğŸ“ æ•°æ®ç›®å½•:")
    data_dir = "data/frames_dataset"
    if os.path.exists(data_dir):
        files = os.listdir(data_dir)
        print(f"âœ… {data_dir}: {len(files)} ä¸ªæ–‡ä»¶")
        for file in files[:3]:
            print(f"   - {file}")
        if len(files) > 3:
            print(f"   ... è¿˜æœ‰ {len(files) - 3} ä¸ªæ–‡ä»¶")
    else:
        print(f"âŒ {data_dir}: ç›®å½•ä¸å­˜åœ¨")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ æ–°å¤šæ™ºèƒ½ä½“ç ”ç©¶ç³»ç»Ÿæµ‹è¯•")
    print("å¼€å§‹æ—¶é—´:", end=" ")
    from datetime import datetime
    print(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)
    
    # ç¯å¢ƒæ£€æŸ¥
    check_environment()
    
    # åŸºæœ¬ç³»ç»Ÿæµ‹è¯•
    await test_new_system()
    
    # FRAMESé£æ ¼æµ‹è¯•
    await test_frames_like_query()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("ğŸ’¡ æç¤º:")
    print("  - å¦‚æœå‡ºç°APIé”™è¯¯ï¼Œè¯·æ£€æŸ¥å¯†é’¥è®¾ç½®")
    print("  - å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£ï¼Œè¯·è¿è¡Œ setup.sh æ„å»ºç´¢å¼•")
    print("  - å®Œæ•´è¯„æµ‹è¯·ä½¿ç”¨ evaluate_frames.py")


if __name__ == "__main__":
    asyncio.run(main())
