"""
æ–‡æœ¬æ‘˜è¦å™¨ï¼šé•¿æ–‡æ¡£æˆªæ–­+å‹ç¼©
"""
import re
from typing import Dict, Any, List, Optional
from config import Config


class SummarizerTool:
    """æ–‡æœ¬æ‘˜è¦å·¥å…·"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‘˜è¦å·¥å…·"""
        self.enabled = Config.ENABLE_SUMMARIZER
        self.max_length = Config.MAX_CONTEXT_LENGTH
        self.planner = None
        self._initialize_planner()
    
    def _initialize_planner(self):
        """åˆå§‹åŒ–è§„åˆ’å™¨ç”¨äºLLMæ‘˜è¦"""
        try:
            from planner.planner import DeepSeekPlanner
            self.planner = DeepSeekPlanner()
        except ImportError as e:
            print(f"âš ï¸ è­¦å‘Š: æ— æ³•å¯¼å…¥è§„åˆ’å™¨ - {e}")
            print("å°†ä½¿ç”¨åŸºç¡€æ‘˜è¦åŠŸèƒ½")
    
    async def summarize(self, text: str, max_length: Optional[int] = None, 
                       style: str = "general") -> Dict[str, Any]:
        """
        å¯¹æ–‡æœ¬è¿›è¡Œæ‘˜è¦
        
        Args:
            text: å¾…æ‘˜è¦çš„æ–‡æœ¬
            max_length: æœ€å¤§æ‘˜è¦é•¿åº¦
            style: æ‘˜è¦é£æ ¼ï¼ˆgeneral/academic/news/bullet_pointsï¼‰
            
        Returns:
            æ‘˜è¦ç»“æœå­—å…¸
        """
        if not text or not text.strip():
            return {
                'summary': '',
                'original_length': 0,
                'summary_length': 0,
                'compression_ratio': 0,
                'method': 'empty',
                'error': 'è¾“å…¥æ–‡æœ¬ä¸ºç©º'
            }
        
        try:
            print(f"ğŸ“ å¼€å§‹æ‘˜è¦ï¼ŒåŸæ–‡é•¿åº¦: {len(text)} å­—ç¬¦")
            
            max_len = max_length or self.max_length // 2
            
            # å¦‚æœæ–‡æœ¬å·²ç»è¶³å¤ŸçŸ­ï¼Œç›´æ¥è¿”å›
            if len(text) <= max_len:
                return {
                    'summary': text,
                    'original_length': len(text),
                    'summary_length': len(text),
                    'compression_ratio': 1.0,
                    'method': 'no_compression',
                    'error': None
                }
            
            # æ ¹æ®æ˜¯å¦æœ‰LLMé€‰æ‹©æ‘˜è¦æ–¹æ³•
            if self.planner and len(text) > 500:
                summary = await self._llm_summarize(text, max_len, style)
                method = 'llm'
            else:
                summary = self._extractive_summarize(text, max_len)
                method = 'extractive'
            
            compression_ratio = len(summary) / len(text)
            
            print(f"âœ… æ‘˜è¦å®Œæˆï¼Œå‹ç¼©æ¯”: {compression_ratio:.2f}")
            
            return {
                'summary': summary,
                'original_length': len(text),
                'summary_length': len(summary),
                'compression_ratio': compression_ratio,
                'method': method,
                'error': None
            }
            
        except Exception as e:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå‡ºé”™: {str(e)}")
            # å‡ºé”™æ—¶è¿”å›æˆªæ–­ç‰ˆæœ¬
            truncated = text[:max_len] + "..." if len(text) > max_len else text
            return {
                'summary': truncated,
                'original_length': len(text),
                'summary_length': len(truncated),
                'compression_ratio': len(truncated) / len(text),
                'method': 'truncation',
                'error': f'æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›æˆªæ–­ç‰ˆæœ¬: {str(e)}'
            }
    
    async def _llm_summarize(self, text: str, max_length: int, 
                           style: str) -> str:
        """
        ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
        
        Args:
            text: åŸæ–‡
            max_length: æœ€å¤§é•¿åº¦
            style: æ‘˜è¦é£æ ¼
            
        Returns:
            LLMç”Ÿæˆçš„æ‘˜è¦
        """
        style_prompts = {
            'general': 'è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œæ‘˜è¦ï¼Œä¿ç•™ä¸»è¦ä¿¡æ¯å’Œå…³é”®ç‚¹ï¼š',
            'academic': 'è¯·å¯¹ä»¥ä¸‹å­¦æœ¯æ–‡æœ¬è¿›è¡Œæ‘˜è¦ï¼Œé‡ç‚¹ä¿ç•™ç ”ç©¶æ–¹æ³•ã€å‘ç°å’Œç»“è®ºï¼š',
            'news': 'è¯·å¯¹ä»¥ä¸‹æ–°é—»æ–‡æœ¬è¿›è¡Œæ‘˜è¦ï¼Œçªå‡ºå…³é”®äº‹å®å’Œé‡è¦ç»†èŠ‚ï¼š',
            'bullet_points': 'è¯·ç”¨è¦ç‚¹å½¢å¼æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦å†…å®¹ï¼š'
        }
        
        prompt = style_prompts.get(style, style_prompts['general'])
        prompt += f"\n\nåŸæ–‡ï¼š\n{text}\n\nè¦æ±‚ï¼š\n1. æ‘˜è¦é•¿åº¦ä¸è¶…è¿‡{max_length}å­—ç¬¦\n2. ä¿æŒåŸæ–‡çš„æ ¸å¿ƒä¿¡æ¯\n3. è¯­è¨€ç®€æ´æ¸…æ™°"
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬æ‘˜è¦ä¸“å®¶ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            summary = await self.planner.generate_response(messages)
            
            # å¦‚æœæ‘˜è¦ä»ç„¶è¿‡é•¿ï¼Œè¿›è¡Œæˆªæ–­
            if len(summary) > max_length:
                summary = summary[:max_length].rsplit('ã€‚', 1)[0] + 'ã€‚'
            
            return summary
        except:
            # LLMå¤±è´¥æ—¶å›é€€åˆ°æŠ½å–å¼æ‘˜è¦
            return self._extractive_summarize(text, max_length)
    
    def _extractive_summarize(self, text: str, max_length: int) -> str:
        """
        æŠ½å–å¼æ‘˜è¦ï¼ˆåŸºäºè§„åˆ™ï¼‰
        
        Args:
            text: åŸæ–‡
            max_length: æœ€å¤§é•¿åº¦
            
        Returns:
            æŠ½å–å¼æ‘˜è¦
        """
        # åˆ†å‰²æˆå¥å­
        sentences = self._split_sentences(text)
        
        if not sentences:
            return text[:max_length]
        
        # è®¡ç®—å¥å­é‡è¦æ€§åˆ†æ•°
        scored_sentences = []
        for i, sentence in enumerate(sentences):
            score = self._calculate_sentence_score(sentence, i, len(sentences))
            scored_sentences.append((sentence, score, i))
        
        # æŒ‰åˆ†æ•°æ’åº
        scored_sentences.sort(key=lambda x: x[1], reverse=True)
        
        # é€‰æ‹©æœ€é‡è¦çš„å¥å­ï¼Œç›´åˆ°è¾¾åˆ°é•¿åº¦é™åˆ¶
        selected_sentences = []
        current_length = 0
        
        for sentence, score, original_index in scored_sentences:
            if current_length + len(sentence) <= max_length:
                selected_sentences.append((sentence, original_index))
                current_length += len(sentence)
            else:
                break
        
        # æŒ‰åŸå§‹é¡ºåºæ’åº
        selected_sentences.sort(key=lambda x: x[1])
        
        # ç»„åˆæ‘˜è¦
        summary = ''.join([sentence for sentence, _ in selected_sentences])
        
        return summary.strip()
    
    def _split_sentences(self, text: str) -> List[str]:
        """
        åˆ†å‰²æ–‡æœ¬ä¸ºå¥å­
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å¥å­åˆ—è¡¨
        """
        # ç®€å•çš„å¥å­åˆ†å‰²ï¼ˆåŸºäºæ ‡ç‚¹ç¬¦å·ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼›\n]+', text)
        
        # æ¸…ç†å’Œè¿‡æ»¤
        cleaned_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 10:  # è¿‡æ»¤è¿‡çŸ­çš„å¥å­
                cleaned_sentences.append(sentence + 'ã€‚')
        
        return cleaned_sentences
    
    def _calculate_sentence_score(self, sentence: str, position: int, 
                                total_sentences: int) -> float:
        """
        è®¡ç®—å¥å­é‡è¦æ€§åˆ†æ•°
        
        Args:
            sentence: å¥å­æ–‡æœ¬
            position: å¥å­åœ¨æ–‡æ¡£ä¸­çš„ä½ç½®
            total_sentences: æ€»å¥å­æ•°
            
        Returns:
            é‡è¦æ€§åˆ†æ•°
        """
        score = 0.0
        
        # ä½ç½®ç‰¹å¾ï¼šå¼€å¤´å’Œç»“å°¾çš„å¥å­æ›´é‡è¦
        if position == 0:
            score += 0.3
        elif position == total_sentences - 1:
            score += 0.2
        elif position < total_sentences * 0.2:
            score += 0.1
        
        # é•¿åº¦ç‰¹å¾ï¼šé€‚ä¸­é•¿åº¦çš„å¥å­æ›´é‡è¦
        sentence_len = len(sentence)
        if 20 <= sentence_len <= 100:
            score += 0.2
        elif sentence_len > 100:
            score += 0.1
        
        # å…³é”®è¯ç‰¹å¾
        important_words = [
            'é‡è¦', 'å…³é”®', 'ä¸»è¦', 'æ ¸å¿ƒ', 'åŸºæœ¬', 'æ˜¾è‘—', 'æ˜æ˜¾',
            'ç ”ç©¶', 'å‘ç°', 'ç»“æœ', 'ç»“è®º', 'æ–¹æ³•', 'åˆ†æ',
            'å› æ­¤', 'æ‰€ä»¥', 'æ€»ä¹‹', 'ç»¼ä¸Š', 'å¯è§'
        ]
        
        for word in important_words:
            if word in sentence:
                score += 0.1
        
        # æ•°å­—å’Œç»Ÿè®¡æ•°æ®
        if re.search(r'\d+', sentence):
            score += 0.05
        
        # å¼•ç”¨å’Œä¸“æœ‰åè¯
        if re.search(r'[A-Z][a-z]+|ã€Š[^ã€‹]+ã€‹', sentence):
            score += 0.05
        
        return score
    
    async def summarize_multiple(self, texts: List[str], 
                               max_length: int) -> Dict[str, Any]:
        """
        å¯¹å¤šä¸ªæ–‡æœ¬è¿›è¡Œæ‘˜è¦
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            max_length: æ€»çš„æœ€å¤§é•¿åº¦
            
        Returns:
            åˆå¹¶æ‘˜è¦ç»“æœ
        """
        if not texts:
            return {
                'summary': '',
                'total_original_length': 0,
                'summary_length': 0,
                'compression_ratio': 0,
                'individual_summaries': [],
                'error': None
            }
        
        try:
            # ä¸ºæ¯ä¸ªæ–‡æœ¬åˆ†é…é•¿åº¦é…é¢
            per_text_length = max_length // len(texts)
            
            individual_summaries = []
            total_original_length = 0
            
            for i, text in enumerate(texts):
                result = await self.summarize(text, per_text_length)
                individual_summaries.append({
                    'index': i,
                    'original_length': result['original_length'],
                    'summary': result['summary'],
                    'summary_length': result['summary_length']
                })
                total_original_length += result['original_length']
            
            # åˆå¹¶æ‘˜è¦
            combined_summary = '\n\n'.join([
                f"æ–‡æ¡£{item['index']+1}: {item['summary']}" 
                for item in individual_summaries
            ])
            
            return {
                'summary': combined_summary,
                'total_original_length': total_original_length,
                'summary_length': len(combined_summary),
                'compression_ratio': len(combined_summary) / total_original_length if total_original_length > 0 else 0,
                'individual_summaries': individual_summaries,
                'error': None
            }
            
        except Exception as e:
            return {
                'summary': '',
                'total_original_length': sum(len(text) for text in texts),
                'summary_length': 0,
                'compression_ratio': 0,
                'individual_summaries': [],
                'error': f'å¤šæ–‡æ¡£æ‘˜è¦å¤±è´¥: {str(e)}'
            }
    
    def get_tool_info(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯"""
        return {
            'name': 'summarize_text',
            'description': 'å¯¹é•¿æ–‡æœ¬è¿›è¡Œæ‘˜è¦å’Œå‹ç¼©',
            'parameters': {
                'text': 'å¾…æ‘˜è¦çš„æ–‡æœ¬',
                'max_length': 'æœ€å¤§æ‘˜è¦é•¿åº¦ï¼ˆå¯é€‰ï¼‰',
                'style': 'æ‘˜è¦é£æ ¼ï¼šgeneral/academic/news/bullet_pointsï¼ˆå¯é€‰ï¼‰'
            },
            'example_usage': 'summarize_text("é•¿ç¯‡æ–‡ç« å†…å®¹...", max_length=500)',
            'capabilities': [
                'LLMæ™ºèƒ½æ‘˜è¦',
                'æŠ½å–å¼æ‘˜è¦',
                'å¤šæ–‡æ¡£æ‘˜è¦',
                'å¤šç§æ‘˜è¦é£æ ¼',
                'è‡ªåŠ¨å‹ç¼©æ¯”è°ƒèŠ‚'
            ],
            'enabled': self.enabled
        }
    
    def analyze_text_complexity(self, text: str) -> Dict[str, Any]:
        """
        åˆ†ææ–‡æœ¬å¤æ‚åº¦ï¼Œå¸®åŠ©é€‰æ‹©æ‘˜è¦ç­–ç•¥
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å¤æ‚åº¦åˆ†æç»“æœ
        """
        sentences = self._split_sentences(text)
        words = text.split()
        
        # åŸºç¡€ç»Ÿè®¡
        char_count = len(text)
        word_count = len(words)
        sentence_count = len(sentences)
        
        # å¹³å‡å¥é•¿
        avg_sentence_length = char_count / sentence_count if sentence_count > 0 else 0
        avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0
        
        # å¤æ‚åº¦è¯„åˆ†
        complexity_score = 0
        if avg_sentence_length > 50:
            complexity_score += 1
        if avg_word_length > 5:
            complexity_score += 1
        if char_count > 2000:
            complexity_score += 1
        
        # æ¨èç­–ç•¥
        if complexity_score >= 2:
            recommended_method = 'llm'
        elif complexity_score == 1:
            recommended_method = 'extractive'
        else:
            recommended_method = 'truncation'
        
        return {
            'char_count': char_count,
            'word_count': word_count,
            'sentence_count': sentence_count,
            'avg_sentence_length': avg_sentence_length,
            'avg_word_length': avg_word_length,
            'complexity_score': complexity_score,
            'recommended_method': recommended_method
        }
