"""
Webæœç´¢å·¥å…·ï¼šä½¿ç”¨Jina APIè¯»å–Webå†…å®¹
"""
import os
import json
import requests
from typing import List, Dict, Any, Optional
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import Config


class WebSearchTool:
    """Webæœç´¢å·¥å…·"""
    
    def __init__(self):
        """åˆå§‹åŒ–Webæœç´¢å·¥å…·"""
        self.jina_api_key = Config.JINA_API_KEY
        self.enabled = Config.ENABLE_WEB_SEARCH and bool(self.jina_api_key)
        self.knowledge_base_dir = Config.KNOWLEDGE_BASE_DIR

    def _search_via_jina(self, query: str, count: int = 5) -> List[str]:
        """
        ä½¿ç”¨Jina APIæœç´¢Webå†…å®¹
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            count: è¿”å›ç»“æœçš„æ•°é‡
            
        Returns:
            Webé¡µé¢URLåˆ—è¡¨
        """
        try:
            # æ„å»ºJinaæœç´¢URL
            search_url = f"https://s.jina.ai/?q={query.replace(' ', '+')}"
            headers = {
                "Authorization": f"Bearer {self.jina_api_key}",
                "X-Respond-With": "no-content",
                # "X-Site": "https://en.wikipedia.org/wiki/"
            }
            
            response = requests.get(search_url, headers=headers, timeout=30)
            if response.status_code == 200:
                text = response.text
                
                # è§£ææœç´¢ç»“æœï¼Œæå–URL
                urls = []
                lines = text.split('\n')
                
                for line in lines:
                    if line.strip().startswith('[') and 'URL Source:' in line:
                        # æå–URL
                        url_start = line.find('https://')
                        if url_start != -1:
                            url = line[url_start:].strip()
                            urls.append(url)
                            
                            if len(urls) >= count:
                                break
                
                print(f"âœ… æ‰¾åˆ° {len(urls)} ä¸ªWebé¡µé¢URLï¼š{', '.join(urls)}")
                return urls
            else:
                print(f"âš ï¸ Jinaæœç´¢APIè¿”å›çŠ¶æ€ç : {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âŒ Jinaæœç´¢å¤±è´¥: {str(e)}")
            return []
       
    
    
    def _get_content_via_jina(self, url: str) -> str:
        """
        ä½¿ç”¨Jina APIè·å–ç½‘é¡µå†…å®¹
        
        Args:
            url: ç½‘é¡µURL
            
        Returns:
            ç½‘é¡µå†…å®¹
        """
        try:
            # å¦‚æœurlæ˜¯è‹±æ–‡wikiï¼Œè½¬æ¢ä¸ºä¸­æ–‡wiki/é•œåƒwiki
            if "en.wikipedia.org" in url:
                # url = url.replace("en.wikipedia.org", "zh.wikipedia.org/wiki/")
                url = url.replace("en.wikipedia.org/wiki/", "encyclopedia.thefreedictionary.com/")
                print(f"ğŸ”„ è½¬æ¢ä¸ºé•œåƒWikipedia: {url}")
            
            jina_url = f"https://r.jina.ai/{url}"
            headers = {
                # 'Authorization': f'Bearer {self.jina_api_key}'
            }
            
            response = requests.get(jina_url, headers=headers, timeout=30)
            if response.status_code == 200:
                content = response.text
                print(f"âœ… é€šè¿‡Jina APIè·å–å†…å®¹ï¼Œé•¿åº¦: {len(content)}")
                # æå–URLä¸­https://åé¢çš„å†…å®¹ï¼Œå¹¶æ›¿æ¢ç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿
                title = url.split("https://")[-1].replace(".", "_").replace("/", "_").replace(" ", "_")
                self._save_to_knowledge_base(title, content)
                return content
            else:
                print(f"âš ï¸ Jina APIè¿”å›çŠ¶æ€ç : {response.status_code}")
                return f"æ— æ³•é€šè¿‡Jina APIè·å–å†…å®¹: HTTP {response.status_code}"
                        
        except Exception as e:
            print(f"âŒ Jina APIè°ƒç”¨å‡ºé”™: {str(e)}")
            return f"Jina APIè°ƒç”¨å¤±è´¥: {str(e)}"
        
    
    def _save_to_knowledge_base(self, title: str, content: str) -> Optional[str]:
        """
        å°†å†…å®¹ä¿å­˜åˆ°çŸ¥è¯†åº“
        
        Args:
            title: æ–‡æ¡£æ ‡é¢˜
            content: æ–‡æ¡£å†…å®¹
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # ç¡®ä¿çŸ¥è¯†åº“ç›®å½•å­˜åœ¨
            os.makedirs(self.knowledge_base_dir, exist_ok=True)
            
            filename = f"{title}.txt"
            filepath = os.path.join(self.knowledge_base_dir, filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(filepath):
                print(f"ğŸ“„ æ–‡ä»¶å·²å­˜åœ¨: {filename}")
                return filepath
            
            # å‡†å¤‡æ–‡æ¡£å†…å®¹ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
            document_content = f"{content}"

            
            # ä¿å­˜æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(document_content)
            
            print(f"ğŸ’¾ å·²ä¿å­˜åˆ°çŸ¥è¯†åº“: {filename}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¿å­˜åˆ°çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
            return None
    

if __name__ == "__main__":
    # æµ‹è¯•å·¥å…·
    web_search_tool = WebSearchTool()

    # æµ‹è¯•æœç´¢åŠŸèƒ½
    urls = web_search_tool._search_via_jina("Artificial Intelligence", count=3)
    print(f"æœç´¢ç»“æœ: {urls}")
    
    # æµ‹è¯•è·å–å†…å®¹
    content = web_search_tool._get_content_via_jina("https://en.wikipedia.org/wiki/Artificial_intelligence")
    print(f"å†…å®¹é¢„è§ˆ: {content[:200]}...")