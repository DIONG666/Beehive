"""
äº’è”ç½‘æœç´¢å·¥å…·ï¼šå¯é€‰æ¥å…¥ Bing API
"""
import asyncio
import aiohttp
import json
from typing import List, Dict, Any, Optional
from config import Config


class WebSearchTool:
    """ç½‘ç»œæœç´¢å·¥å…·"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç½‘ç»œæœç´¢å·¥å…·"""
        self.bing_api_key = Config.BING_API_KEY
        self.enabled = Config.ENABLE_WEB_SEARCH and bool(self.bing_api_key)
        self.bing_endpoint = "https://api.bing.microsoft.com/v7.0/search"
    
    async def search(self, query: str, count: int = 10, 
                    market: str = "zh-CN") -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œç½‘ç»œæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            count: è¿”å›ç»“æœæ•°é‡
            market: æœç´¢å¸‚åœºï¼ˆè¯­è¨€å’Œåœ°åŒºï¼‰
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.enabled:
            return [{
                'title': 'ç½‘ç»œæœç´¢åŠŸèƒ½æœªå¯ç”¨',
                'content': 'è¯·é…ç½®BING_API_KEYä»¥å¯ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½',
                'url': '',
                'source': 'web_search_disabled',
                'error': True
            }]
        
        try:
            print(f"ğŸŒ åœ¨ç½‘ç»œä¸Šæœç´¢: {query}")
            
            # æ„å»ºæœç´¢å‚æ•°
            params = {
                'q': query,
                'count': count,
                'mkt': market,
                'responseFilter': 'webpages',
                'textDecorations': False,
                'textFormat': 'Raw'
            }
            
            headers = {
                'Ocp-Apim-Subscription-Key': self.bing_api_key,
                'User-Agent': 'Multi-Agent Research System/1.0'
            }
            
            # å‘èµ·æœç´¢è¯·æ±‚
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    self.bing_endpoint, 
                    params=params, 
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status != 200:
                        raise Exception(f"Bing APIè¿”å›é”™è¯¯çŠ¶æ€ç : {response.status}")
                    
                    data = await response.json()
                    return self._parse_bing_results(data)
                    
        except Exception as e:
            print(f"âŒ ç½‘ç»œæœç´¢å‡ºé”™: {str(e)}")
            return [{
                'title': 'ç½‘ç»œæœç´¢é”™è¯¯',
                'content': f'æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}',
                'url': '',
                'source': 'web_search_error',
                'error': True
            }]
    
    def _parse_bing_results(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        è§£æBingæœç´¢ç»“æœ
        
        Args:
            data: Bing APIè¿”å›çš„åŸå§‹æ•°æ®
            
        Returns:
            æ ¼å¼åŒ–çš„æœç´¢ç»“æœ
        """
        results = []
        
        if 'webPages' not in data or 'value' not in data['webPages']:
            return results
        
        for item in data['webPages']['value']:
            result = {
                'title': item.get('name', ''),
                'content': item.get('snippet', ''),
                'url': item.get('url', ''),
                'source': 'web_search',
                'display_url': item.get('displayUrl', ''),
                'last_crawled': item.get('dateLastCrawled', ''),
                'score': 1.0  # Bingä¸æä¾›ç›¸å…³æ€§è¯„åˆ†ï¼Œç»Ÿä¸€è®¾ä¸º1.0
            }
            results.append(result)
        
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç½‘ç»œæœç´¢ç»“æœ")
        return results
    
    async def search_news(self, query: str, count: int = 10) -> List[Dict[str, Any]]:
        """
        æœç´¢æ–°é—»
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            count: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æ–°é—»æœç´¢ç»“æœ
        """
        if not self.enabled:
            return []
        
        try:
            news_endpoint = "https://api.bing.microsoft.com/v7.0/news/search"
            
            params = {
                'q': query,
                'count': count,
                'mkt': 'zh-CN',
                'sortBy': 'Date'
            }
            
            headers = {
                'Ocp-Apim-Subscription-Key': self.bing_api_key,
                'User-Agent': 'Multi-Agent Research System/1.0'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    news_endpoint,
                    params=params,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status != 200:
                        return []
                    
                    data = await response.json()
                    return self._parse_news_results(data)
                    
        except Exception as e:
            print(f"âŒ æ–°é—»æœç´¢å‡ºé”™: {str(e)}")
            return []
    
    def _parse_news_results(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è§£ææ–°é—»æœç´¢ç»“æœ"""
        results = []
        
        if 'value' not in data:
            return results
        
        for item in data['value']:
            result = {
                'title': item.get('name', ''),
                'content': item.get('description', ''),
                'url': item.get('url', ''),
                'source': 'news_search',
                'published_time': item.get('datePublished', ''),
                'provider': item.get('provider', [{}])[0].get('name', '') if item.get('provider') else '',
                'score': 1.0
            }
            results.append(result)
        
        return results
    
    async def search_academic(self, query: str, count: int = 10) -> List[Dict[str, Any]]:
        """
        æœç´¢å­¦æœ¯èµ„æºï¼ˆé€šè¿‡ç‰¹å®šçš„å­¦æœ¯ç½‘ç«™ï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            count: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            å­¦æœ¯æœç´¢ç»“æœ
        """
        # æ·»åŠ å­¦æœ¯ç›¸å…³çš„æœç´¢è¯
        academic_query = f"{query} site:arxiv.org OR site:scholar.google.com OR site:researchgate.net OR site:ieee.org"
        
        results = await self.search(academic_query, count)
        
        # æ ‡è®°ä¸ºå­¦æœ¯æ¥æº
        for result in results:
            result['source'] = 'academic_search'
        
        return results
    
    async def verify_url(self, url: str) -> bool:
        """
        éªŒè¯URLæ˜¯å¦å¯è®¿é—®
        
        Args:
            url: å¾…éªŒè¯çš„URL
            
        Returns:
            URLæ˜¯å¦å¯è®¿é—®
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.head(
                    url,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    return response.status == 200
        except:
            return False
    
    def get_tool_info(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯"""
        return {
            'name': 'web_search',
            'description': 'åœ¨äº’è”ç½‘ä¸Šæœç´¢æœ€æ–°ä¿¡æ¯å’Œèµ„æº',
            'parameters': {
                'query': 'æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²',
                'count': 'è¿”å›ç»“æœæ•°é‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤10ï¼‰',
                'search_type': 'æœç´¢ç±»å‹ï¼šweb/news/academicï¼ˆå¯é€‰ï¼‰'
            },
            'example_usage': 'web_search("2024å¹´äººå·¥æ™ºèƒ½æœ€æ–°è¿›å±•")',
            'capabilities': [
                'ç½‘é¡µæœç´¢',
                'æ–°é—»æœç´¢', 
                'å­¦æœ¯èµ„æºæœç´¢',
                'URLéªŒè¯'
            ],
            'enabled': self.enabled
        }
    
    async def get_page_content(self, url: str, max_length: int = 2000) -> str:
        """
        è·å–ç½‘é¡µå†…å®¹ï¼ˆç®€å•ç‰ˆæœ¬ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
        
        Args:
            url: ç½‘é¡µURL
            max_length: æœ€å¤§å†…å®¹é•¿åº¦
            
        Returns:
            ç½‘é¡µæ–‡æœ¬å†…å®¹
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url,
                    timeout=aiohttp.ClientTimeout(total=15),
                    headers={
                        'User-Agent': 'Multi-Agent Research System/1.0'
                    }
                ) as response:
                    
                    if response.status != 200:
                        return ""
                    
                    content = await response.text()
                    
                    # ç®€å•çš„HTMLæ ‡ç­¾æ¸…ç†ï¼ˆå®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨BeautifulSoupï¼‰
                    import re
                    text = re.sub(r'<[^>]+>', '', content)
                    text = re.sub(r'\s+', ' ', text).strip()
                    
                    return text[:max_length] if len(text) > max_length else text
                    
        except Exception as e:
            print(f"âŒ è·å–ç½‘é¡µå†…å®¹å‡ºé”™: {str(e)}")
            return ""
